{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have single datasets for each type of \"factor\" that people might take in consideration when deciding what country to live in, but we need to merge all of them into one single dataset in order to build models with this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 5 datasets in total:\n",
    "- cost of living\n",
    "- healthcare index\n",
    "- safety index\n",
    "- internet speed\n",
    "- average temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cost_of_living = pd.read_csv(\"../raw_data/Alternative_sources_country_level/cost_expense.csv\")\n",
    "healthcare = pd.read_csv(\"../raw_data/Alternative_sources_country_level/healthcare_index.csv\")\n",
    "climate = pd.read_csv(\"../raw_data/Alternative_sources_country_level/climate_avarage_temperature.csv\")\n",
    "internet = pd.read_csv(\"../raw_data/Alternative_sources_country_level/internet_speed_rankings.csv\")\n",
    "safety = pd.read_csv(\"../raw_data/Alternative_sources_country_level/safety_index_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the columns we need for now, rename them with explanative names and set the index to country for all datasets\n",
    "\n",
    "#cost of living\n",
    "cost_of_living = cost_of_living[['country', 'average_monthly_cost($)']]\n",
    "cost_of_living.columns = ['Country', 'average_monthly_cost_$']\n",
    "cost_of_living.set_index('Country', inplace=True)\n",
    "\n",
    "# healthcare dataset\n",
    "healthcare = healthcare[['Country', 'Health Care Index']]\n",
    "healthcare.columns = ['Country', 'Healthcare Index']\n",
    "healthcare.set_index('Country', inplace=True)\n",
    "\n",
    "# climate dataset\n",
    "climate = climate[['Country', 'Temperature']]\n",
    "climate.columns = ['Country', 'average_yearly_temperature']\n",
    "climate.set_index('Country', inplace=True)\n",
    "\n",
    "# internet dataset\n",
    "internet = internet[['Country', 'Internet Speed (Mbps)']]\n",
    "internet.columns = ['Country', 'internet_speed_mbps']\n",
    "internet.set_index('Country', inplace=True)\n",
    "\n",
    "# safety dataset\n",
    "safety = safety[['Country', 'Safety Index']]\n",
    "safety.columns = ['Country', 'safety_index']\n",
    "safety.set_index('Country', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique countries across all datasets: 255\n",
      "Countries common to all datasets: 116\n",
      "Countries that would be lost in a direct merge: 139\n",
      "\n",
      "Dataset coverage:\n",
      "Cost of living dataset: 172 countries\n",
      "Climate dataset: 178 countries\n",
      "Internet dataset: 155 countries\n",
      "Safety dataset: 147 countries\n",
      "Healthcare dataset: 236 countries\n"
     ]
    }
   ],
   "source": [
    "#Now let's understand how the Country indexes are misaligned between the datasets\n",
    "\n",
    "\n",
    "# 1. Assess misalignment between datasets\n",
    "\n",
    "# Get all unique country names from each dataset\n",
    "countries_cost = set(cost_of_living.index)\n",
    "countries_climate = set(climate.index)\n",
    "countries_internet = set(internet.index)\n",
    "countries_safety = set(safety.index)\n",
    "countries_healthcare = set(healthcare.index)\n",
    "\n",
    "# Count total unique countries across all datasets\n",
    "all_countries = countries_cost.union(countries_climate, countries_internet, countries_safety, countries_healthcare)\n",
    "print(f\"Total unique countries across all datasets: {len(all_countries)}\")\n",
    "\n",
    "# Check how many countries are common across all datasets\n",
    "common_countries = countries_cost.intersection(countries_climate, countries_internet, countries_safety, countries_healthcare)\n",
    "print(f\"Countries common to all datasets: {len(common_countries)}\")\n",
    "print(f\"Countries that would be lost in a direct merge: {len(all_countries) - len(common_countries)}\")\n",
    "\n",
    "# Check dataset-specific coverage\n",
    "print(f\"\\nDataset coverage:\")\n",
    "print(f\"Cost of living dataset: {len(countries_cost)} countries\")\n",
    "print(f\"Climate dataset: {len(countries_climate)} countries\")\n",
    "print(f\"Internet dataset: {len(countries_internet)} countries\")\n",
    "print(f\"Safety dataset: {len(countries_safety)} countries\")\n",
    "print(f\"Healthcare dataset: {len(countries_healthcare)} countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After standardization:\n",
      "Countries common to all datasets: 119\n"
     ]
    }
   ],
   "source": [
    "# 2. Standardize country names\n",
    "\n",
    "# Create a function to standardize country names\n",
    "def standardize_country_name(name):\n",
    "    # Convert to lowercase for comparison\n",
    "    name = name.lower()\n",
    "    \n",
    "    # Replacements to be made manually\n",
    "    easy_replacements = {\n",
    "        'democratic republic of the congo': 'congo',\n",
    "        'republic of the congo': 'congo',\n",
    "        'hong kong (sar)': 'hong kong',\n",
    "        'macau (sar)': 'macau',\n",
    "        'trinidad and tobago': 'trinidad & tobago',\n",
    "        'bosnia and herzegovina': 'bosnia & herzegovina',\n",
    "        'antigua and barbuda': 'antigua & barbuda',\n",
    "    }\n",
    "    \n",
    "    # Apply replacements\n",
    "    for old, new in easy_replacements.items():\n",
    "        if name == old:\n",
    "            return new\n",
    "    \n",
    "    # Remove common prefixes/suffixes\n",
    "    prefixes = ['republic of ', 'the ', 'democratic republic of ', 'federation of ']\n",
    "    for prefix in prefixes:\n",
    "        if name.startswith(prefix):\n",
    "            name = name[len(prefix):]\n",
    "    \n",
    "    # Remove spaces and special characters for comparison\n",
    "    name = name.replace(' and ', ' & ')\n",
    "    \n",
    "    return name\n",
    "\n",
    "# Create standardized versions of each dataset\n",
    "def standardize_dataset(df):\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_std = df.copy()\n",
    "    \n",
    "    # Create a mapping of original to standardized names\n",
    "    name_mapping = {idx: standardize_country_name(idx) for idx in df.index}\n",
    "    \n",
    "    # Create a new index with standardized names\n",
    "    df_std.index = [name_mapping[idx] for idx in df.index]\n",
    "    \n",
    "    return df_std, name_mapping\n",
    "\n",
    "# Standardize each dataset\n",
    "cost_of_living_std, cost_mapping = standardize_dataset(cost_of_living)\n",
    "climate_std, climate_mapping = standardize_dataset(climate)\n",
    "internet_std, internet_mapping = standardize_dataset(internet)\n",
    "safety_std, safety_mapping = standardize_dataset(safety)\n",
    "\n",
    "# Check improvement after standardization\n",
    "countries_cost_std = set(cost_of_living_std.index)\n",
    "countries_climate_std = set(climate_std.index)\n",
    "countries_internet_std = set(internet_std.index)\n",
    "countries_safety_std = set(safety_std.index)\n",
    "\n",
    "common_countries_std = countries_cost_std.intersection(countries_climate_std, countries_internet_std, countries_safety_std)\n",
    "print(f\"\\nAfter standardization:\")\n",
    "print(f\"Countries common to all datasets: {len(common_countries_std)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Countries with partial coverage: 111\n",
      "                     in_cost  in_climate  in_internet  in_safety  \\\n",
      "Aland Islands          False       False        False      False   \n",
      "Alderney               False       False        False      False   \n",
      "American Samoa         False       False        False      False   \n",
      "Anguilla               False       False        False      False   \n",
      "Antigua And Barbuda    False       False        False      False   \n",
      "Antigua and Barbuda    False        True         True      False   \n",
      "Aruba                   True       False        False      False   \n",
      "Benin                  False        True         True      False   \n",
      "Bermuda                 True       False        False      False   \n",
      "Bhutan                  True        True        False      False   \n",
      "\n",
      "                     in_healthcare  coverage_pct  \n",
      "Aland Islands                 True          25.0  \n",
      "Alderney                      True          25.0  \n",
      "American Samoa                True          25.0  \n",
      "Anguilla                      True          25.0  \n",
      "Antigua And Barbuda           True          25.0  \n",
      "Antigua and Barbuda          False          50.0  \n",
      "Aruba                         True          50.0  \n",
      "Benin                         True          75.0  \n",
      "Bermuda                       True          50.0  \n",
      "Bhutan                        True          75.0  \n"
     ]
    }
   ],
   "source": [
    "# 3. Analyze country coverage and missing countries\n",
    "\n",
    "# Create a DataFrame to show which countries are in which datasets\n",
    "country_coverage = pd.DataFrame(index=sorted(all_countries))\n",
    "country_coverage['in_cost'] = country_coverage.index.isin(countries_cost)\n",
    "country_coverage['in_climate'] = country_coverage.index.isin(countries_climate)\n",
    "country_coverage['in_internet'] = country_coverage.index.isin(countries_internet)\n",
    "country_coverage['in_safety'] = country_coverage.index.isin(countries_safety)\n",
    "country_coverage['in_healthcare'] = country_coverage.index.isin(countries_healthcare)\n",
    "\n",
    "# Calculate coverage percentage for each country\n",
    "country_coverage['coverage_pct'] = country_coverage.sum(axis=1) / 4 * 100\n",
    "\n",
    "# Show countries with partial coverage\n",
    "partial_coverage = country_coverage[country_coverage['coverage_pct'] < 100]\n",
    "print(f\"\\nCountries with partial coverage: {len(partial_coverage)}\")\n",
    "print(partial_coverage.head(10))  # Show first 10 examples\n",
    "\n",
    "# Create a mapping dictionary for manual corrections\n",
    "manual_corrections = {\n",
    "    # Examples of manual corrections\n",
    "    'United States': 'USA',\n",
    "    'USA': 'United States',\n",
    "    'UK': 'United Kingdom',\n",
    "    'United Kingdom': 'UK',\n",
    "    # Add more as needed based on the analysis\n",
    "}\n",
    "\n",
    "# Function to merge datasets with standardized country names\n",
    "def merge_datasets_with_standardization():\n",
    "    # Create copies with standardized names\n",
    "    cost_std = cost_of_living.copy()\n",
    "    climate_std = climate.copy()\n",
    "    internet_std = internet.copy()\n",
    "    safety_std = safety.copy()\n",
    "    healthcare_std = healthcare.copy()\n",
    "    \n",
    "    # Apply manual corrections to indexes\n",
    "    for dataset in [cost_std, climate_std, internet_std, safety_std, healthcare_std]:\n",
    "        new_index = [manual_corrections.get(country, country) for country in dataset.index]\n",
    "        dataset.index = new_index\n",
    "    \n",
    "    # Merge datasets using inner join to keep only countries present in all datasets\n",
    "    merged = pd.merge(cost_std, climate_std, left_index=True, right_index=True, how='inner')\n",
    "    merged = pd.merge(merged, internet_std, left_index=True, right_index=True, how='inner')\n",
    "    merged = pd.merge(merged, safety_std, left_index=True, right_index=True, how='inner')\n",
    "    merged = pd.merge(merged, healthcare_std, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# This function can be used later when we finalize the standardization approach\n",
    "merged_data = merge_datasets_with_standardization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_monthly_cost_$</th>\n",
       "      <th>average_yearly_temperature</th>\n",
       "      <th>internet_speed_mbps</th>\n",
       "      <th>safety_index</th>\n",
       "      <th>Healthcare Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>960.545000</td>\n",
       "      <td>18.1</td>\n",
       "      <td>3.88</td>\n",
       "      <td>24.9</td>\n",
       "      <td>24.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>518.916429</td>\n",
       "      <td>22.2</td>\n",
       "      <td>81.41</td>\n",
       "      <td>55.3</td>\n",
       "      <td>48.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>356.045500</td>\n",
       "      <td>22.8</td>\n",
       "      <td>16.54</td>\n",
       "      <td>47.4</td>\n",
       "      <td>54.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>740.635000</td>\n",
       "      <td>27.1</td>\n",
       "      <td>22.91</td>\n",
       "      <td>33.7</td>\n",
       "      <td>36.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>503.731250</td>\n",
       "      <td>15.1</td>\n",
       "      <td>93.38</td>\n",
       "      <td>36.6</td>\n",
       "      <td>68.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             average_monthly_cost_$  average_yearly_temperature  \\\n",
       "Afghanistan              960.545000                        18.1   \n",
       "Albania                  518.916429                        22.2   \n",
       "Algeria                  356.045500                        22.8   \n",
       "Angola                   740.635000                        27.1   \n",
       "Argentina                503.731250                        15.1   \n",
       "\n",
       "             internet_speed_mbps  safety_index  Healthcare Index  \n",
       "Afghanistan                 3.88          24.9             24.24  \n",
       "Albania                    81.41          55.3             48.21  \n",
       "Algeria                    16.54          47.4             54.43  \n",
       "Angola                     22.91          33.7             36.58  \n",
       "Argentina                  93.38          36.6             68.00  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv(\"../raw_data/merged_country_level/temporary_merged_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
